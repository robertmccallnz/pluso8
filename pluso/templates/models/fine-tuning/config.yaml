# Fine-tuning Configuration Template

# Base Model Selection
base_model:
  provider: "anthropic"  # anthropic, openai
  model: "claude-3-sonnet"
  version: "20240307"

# Training Configuration
training:
  epochs: 3
  batch_size: 32
  learning_rate: 2e-5
  warmup_steps: 500
  max_steps: 10000
  evaluation_strategy: "steps"
  eval_steps: 500
  save_steps: 1000
  logging_steps: 100

# Dataset Configuration
dataset:
  train_path: "./datasets/train.jsonl"
  eval_path: "./datasets/eval.jsonl"
  test_path: "./datasets/test.jsonl"
  format: "jsonl"
  validation_split: 0.1
  test_split: 0.1
  max_length: 2048
  preprocessing:
    clean_text: true
    remove_duplicates: true
    balance_classes: true

# Optimization
optimization:
  weight_decay: 0.01
  gradient_accumulation_steps: 4
  max_grad_norm: 1.0
  fp16: true
  bf16: false

# Model Specific Settings
model_config:
  attention_probs_dropout_prob: 0.1
  hidden_dropout_prob: 0.1
  hidden_size: 768
  intermediate_size: 3072
  num_attention_heads: 12
  num_hidden_layers: 12
  vocab_size: 50257

# Evaluation Metrics
evaluation:
  metrics:
    - "accuracy"
    - "f1"
    - "precision"
    - "recall"
    - "rouge"
    - "bleu"
  custom_metrics:
    - name: "domain_accuracy"
      script: "./evaluation/domain_metrics.py"
    - name: "response_quality"
      script: "./evaluation/quality_metrics.py"

# Early Stopping
early_stopping:
  enabled: true
  metric: "eval_loss"
  patience: 3
  min_delta: 0.001
  mode: "min"

# Checkpointing
checkpointing:
  enabled: true
  save_total_limit: 3
  save_best_only: true
  metric_for_best: "eval_loss"
  greater_is_better: false

# Hardware Configuration
hardware:
  accelerator: "gpu"  # cpu, gpu, tpu
  devices: 1
  precision: 16  # 16, 32, bf16
  distributed_strategy: "none"  # none, ddp, deepspeed

# Monitoring
monitoring:
  tensorboard: true
  wandb:
    enabled: true
    project: "pluso-fine-tuning"
    entity: "pluso"
    tags: ["fine-tuning", "production"]
    contact: "hello@pluso.co.nz"

# Export Configuration
export:
  format: "onnx"  # onnx, tensorflow, pytorch
  quantization: "int8"  # none, int8, float16
  optimization_level: 3  # 0-3
  target_devices: ["cpu", "gpu"]
